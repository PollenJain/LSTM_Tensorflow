{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' https://github.com/roatienza/Deep-Learning-Experiments/blob/master/Experiments/Tensorflow/RNN/rnn_words.py '''\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_file = 'input_text.txt'\n",
    "\n",
    "def read(filename):\n",
    "    file_handler = open(filename)\n",
    "    ''' To get content as a string, use file_handler.read()'''\n",
    "    content_in_a_list = file_handler.readlines() # Returns the entire file content in a list. Delimiter is \\n and not full stop.\n",
    "    file_handler.close()\n",
    "#     print(content_in_a_list)\n",
    "#     print(len(content_in_a_list))\n",
    "    content = [x.strip() for x in content_in_a_list] # Strips trailing whitespaces\n",
    "#     print(content)\n",
    "    ''' Split each sentence into words'''\n",
    "    content = [content[i].split() for i in range(len(content))] # List of lists\n",
    "#     print(content)\n",
    "    content = np.array(content) # Therefore, it'll become a 2-dimensional numpy array\n",
    "#     print(content.shape) # (1, 204)\n",
    "    content = np.reshape(content, [-1,]) # Converting 2-dimensional numpy array to 1-dimensional array\n",
    "#     print(content.shape) # (204, )\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Loading Data---\n"
     ]
    }
   ],
   "source": [
    "print(\"---Loading Data---\")\n",
    "\n",
    "''' training_data is a 1-dimensional numpy array with each element as a word from the file. Words can repeat'''\n",
    "training_data = read(training_file) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "''' return 2 dictionaries: 1. word (not character) as key to index as value\n",
    "                           2. index as key to word (not character) as value\n",
    "                           \n",
    "word having maximum frequency is assigned index as 0\n",
    "words having same frequency are arbitarily given increementing index\n",
    "'''\n",
    "def build_dataset(list_of_words):\n",
    "#         list_of_words = list(list_of_words)\n",
    "#         word_count = np.array([(word, list_of_words.count(word)) for word in list_of_words])\n",
    "        count = collections.Counter(list_of_words).most_common() # Taking in numpy array outputs a python list\n",
    "#         print(count)\n",
    "#      print(type(count))\n",
    "#           print(len(count))\n",
    "       \n",
    "        ''' Easy to understand implementation'''\n",
    "        word_to_ix = dict()\n",
    "        ix = 0\n",
    "        ix_to_word = dict()\n",
    "        for word_, count_ in count:\n",
    "            if word_ not in word_to_ix:\n",
    "                    word_to_ix[word_] = ix\n",
    "            \n",
    "            if ix not in ix_to_word:\n",
    "                ix_to_word[ix] = word_\n",
    "                \n",
    "            ix = ix + 1\n",
    "            \n",
    "        ''' Intelligent implementation '''\n",
    "        word_to_index = dict()\n",
    "        for word_, count_ in count:\n",
    "                if word_ not in word_to_index:\n",
    "                    word_to_index[word_] = len(word_to_index)\n",
    "                \n",
    "        \n",
    "        index_to_word = dict(zip(word_to_index.values(), word_to_index.keys()))\n",
    "        \n",
    "        return word_to_ix, ix_to_word\n",
    "        \n",
    "            \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'then': 94, 'neck': 37, 'spoke': 38, 'approaches': 39, 'measures': 40, 'easily': 17, 'when': 41, 'had': 21, 'means': 43, 'common': 44, 'a': 6, 'an': 45, 'signal': 97, '.': 2, 'neighbourhood': 46, 'consists': 47, 'thought': 48, 'ribbon': 105, 'said': 4, 'danger': 49, 'was': 18, 'until': 50, 'us': 51, 'in': 11, 'i': 52, 'know': 108, 'ago': 53, 'she': 19, 'receive': 54, 'take': 55, 'will': 56, 'which': 20, 'case': 57, 'now': 58, 'procured': 59, 'what': 60, 'if': 61, 'he': 9, 'meet': 62, 'from': 103, 'all': 22, 'propose': 23, '?': 64, 'you': 65, 'some': 12, 'would': 66, 'remedies': 67, 'looked': 68, 'met': 69, 'but': 24, 'should': 70, 'escape': 72, 'by': 25, 'impossible': 73, 'very': 74, 'at': 26, 'old': 27, 'attached': 75, 'approach': 104, 'therefore': 77, 'could': 7, 'who': 78, 'council': 79, 'chief': 80, 'venture': 81, 'outwit': 82, 'about': 83, 'treacherous': 84, 'mice': 28, ',': 0, 'they': 85, 'her': 33, 'the': 1, 'manner': 86, 'up': 29, 'is': 13, 'consider': 88, 'general': 30, 'to': 5, 'that': 8, 'bell': 31, 'of': 32, 'small': 89, 'applause': 87, 'agree': 90, 'make': 91, 'got': 34, 'well': 92, 'our': 93, 'easy': 63, 'with': 95, 'long': 96, 'this': 10, 'young': 98, 'last': 99, 'round': 100, 'mouse': 14, 'their': 101, 'retire': 102, 'and': 3, 'it': 76, 'nobody': 71, 'we': 15, 'always': 106, 'proposal': 35, 'another': 107, 'one': 42, 'enemy': 36, 'cat': 16, 'sly': 109, 'be': 110, 'while': 111}\n"
     ]
    }
   ],
   "source": [
    "word_to_ix, ix_to_word = build_dataset(training_data)\n",
    "print(word_to_ix)\n",
    "# print(ix_to_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' Works: My implementation of build_dataset'''\n",
    "\n",
    "def build_my_dataset(list_of_words):\n",
    "    ''' These two lines are same as collections.Counter(list_of_words).most_common()'''\n",
    "    list_of_words = list(list_of_words)\n",
    "    word_count = sorted(list(set([(word,list_of_words.count(word))for word in list_of_words])), key=lambda x:x[1], reverse=True)\n",
    "#     print(word_count)\n",
    "#     print(len(word_count))\n",
    "\n",
    "    \n",
    "    ''' Easy to understand implementation'''\n",
    "    word_to_ix = dict()\n",
    "    ix = 0\n",
    "    ix_to_word = dict()\n",
    "    for word_, count_ in word_count:\n",
    "        if word_ not in word_to_ix:\n",
    "                word_to_ix[word_] = ix\n",
    "            \n",
    "        if ix not in ix_to_word:\n",
    "                ix_to_word[ix] = word_\n",
    "                \n",
    "        ix = ix + 1\n",
    "            \n",
    "    return word_to_ix, ix_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# word_to_ix, ix_to_word = build_my_dataset(training_data)\n",
    "vocab_size = len(word_to_ix) # one-hot encoded output vector will be of shape (vocab_size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib import rnn\n",
    "\n",
    "n_hidden = 512\n",
    "n_input = 3\n",
    "learning_rate = 0.001\n",
    "no_of_words_to_be_passed_as_input_at_a_time = 3\n",
    "\n",
    "\n",
    "# Placeholders\n",
    "x = tf.placeholder(tf.float32, [None, n_input, 1])\n",
    "y = tf.placeholder(tf.float32, [None, vocab_size])\n",
    "\n",
    "weights = {\n",
    "    'out' : tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([vocab_size]))\n",
    "}\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "    # x is passed like this: [ [ [11], [2], [15] ] ]\n",
    "    x = tf.reshape(x, (-1, no_of_words_to_be_passed_as_input_at_a_time))\n",
    "    # x becomes [ [11, 2, 15] ]\n",
    "    x1 = tf.split(x, no_of_words_to_be_passed_as_input_at_a_time, 1) # [ [ [11] ], [ [2] ], [ [15] ] ]\n",
    "    \n",
    "#     rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden), rnn.BasicLSTMCell(n_hidden)])\n",
    "    rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
    "\n",
    "    # generate predictions\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x1, dtype=tf.float32)\n",
    "    \n",
    "#     # there are n_input outputs but\n",
    "    # we only want the last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = RNN(x, weights, biases)\n",
    "\n",
    "# Loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Model evaluation\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Average Loss 0.0669912624359\n",
      "Average Accuracy 0.0\n",
      "words in sequence: ['long', 'ago', ',']\n",
      "next word in sequence: the\n",
      "next word predicted for sequence: could\n",
      "Iteration 100\n",
      "Average Loss 10.3914401615\n",
      "Average Accuracy 2.0\n",
      "words in sequence: ['is', 'easy', 'to']\n",
      "next word in sequence: propose\n",
      "next word predicted for sequence: nobody\n",
      "Iteration 200\n",
      "Average Loss 6.77364338636\n",
      "Average Accuracy 0.0\n",
      "words in sequence: ['is', 'easy', 'to']\n",
      "next word in sequence: propose\n",
      "next word predicted for sequence: nobody\n",
      "Iteration 300\n",
      "Average Loss 6.95348080337\n",
      "Average Accuracy 2.0\n",
      "words in sequence: ['easy', 'to', 'propose']\n",
      "next word in sequence: impossible\n",
      "next word predicted for sequence: bell\n",
      "Iteration 400\n",
      "Average Loss 5.91246271372\n",
      "Average Accuracy 5.0\n",
      "words in sequence: ['it', 'is', 'easy']\n",
      "next word in sequence: to\n",
      "next word predicted for sequence: ,\n",
      "Iteration 500\n",
      "Average Loss 5.98596815467\n",
      "Average Accuracy 2.0\n",
      "words in sequence: ['said', 'it', 'is']\n",
      "next word in sequence: easy\n",
      "next word predicted for sequence: mouse\n",
      "Iteration 600\n",
      "Average Loss 4.59697749048\n",
      "Average Accuracy 3.0\n",
      "words in sequence: ['nobody', 'spoke', '.']\n",
      "next word in sequence: then\n",
      "next word predicted for sequence: cat\n",
      "Iteration 700\n",
      "Average Loss 4.52411679208\n",
      "Average Accuracy 7.0\n",
      "words in sequence: ['another', 'and', 'nobody']\n",
      "next word in sequence: spoke\n",
      "next word predicted for sequence: ,\n",
      "Iteration 800\n",
      "Average Loss 4.8108715421\n",
      "Average Accuracy 6.0\n",
      "words in sequence: ['at', 'one', 'another']\n",
      "next word in sequence: and\n",
      "next word predicted for sequence: well\n",
      "Iteration 900\n",
      "Average Loss 5.49275674224\n",
      "Average Accuracy 5.0\n",
      "words in sequence: ['the', 'mice', 'looked']\n",
      "next word in sequence: at\n",
      "next word predicted for sequence: ,\n",
      "Iteration 1000\n",
      "Average Loss 3.6294567436\n",
      "Average Accuracy 12.0\n",
      "words in sequence: ['to', 'bell', 'the']\n",
      "next word in sequence: cat\n",
      "next word predicted for sequence: that\n",
      "Iteration 1100\n",
      "Average Loss 5.05074271679\n",
      "Average Accuracy 6.0\n",
      "words in sequence: ['who', 'is', 'to']\n",
      "next word in sequence: bell\n",
      "next word predicted for sequence: but\n",
      "Iteration 1200\n",
      "Average Loss 4.00390630424\n",
      "Average Accuracy 3.0\n",
      "words in sequence: [',', 'but', 'who']\n",
      "next word in sequence: is\n",
      "next word predicted for sequence: well\n",
      "Iteration 1300\n",
      "Average Loss 3.37463430315\n",
      "Average Accuracy 11.0\n",
      "words in sequence: ['very', 'well', ',']\n",
      "next word in sequence: but\n",
      "next word predicted for sequence: and\n",
      "Iteration 1400\n",
      "Average Loss 3.16114822656\n",
      "Average Accuracy 11.0\n",
      "words in sequence: ['said', 'that', 'is']\n",
      "next word in sequence: all\n",
      "next word predicted for sequence: a\n",
      "Iteration 1500\n",
      "Average Loss 3.81308366226\n",
      "Average Accuracy 17.0\n",
      "words in sequence: ['and', 'said', 'that']\n",
      "next word in sequence: is\n",
      "next word predicted for sequence: had\n",
      "Iteration 1600\n",
      "Average Loss 4.721851504\n",
      "Average Accuracy 8.0\n",
      "words in sequence: ['said', 'that', 'is']\n",
      "next word in sequence: all\n",
      "next word predicted for sequence: the\n",
      "Iteration 1700\n",
      "Average Loss 3.61224986345\n",
      "Average Accuracy 6.0\n",
      "words in sequence: ['and', 'said', 'that']\n",
      "next word in sequence: is\n",
      "next word predicted for sequence: retire\n",
      "Iteration 1800\n",
      "Average Loss 3.42484855261\n",
      "Average Accuracy 15.0\n",
      "words in sequence: ['an', 'old', 'mouse']\n",
      "next word in sequence: got\n",
      "next word predicted for sequence: about\n",
      "Iteration 1900\n",
      "Average Loss 4.47263319537\n",
      "Average Accuracy 14.0\n",
      "words in sequence: ['applause', ',', 'until']\n",
      "next word in sequence: an\n",
      "next word predicted for sequence: an\n",
      "Iteration 2000\n",
      "Average Loss 3.21740346551\n",
      "Average Accuracy 13.0\n",
      "words in sequence: ['applause', ',', 'until']\n",
      "next word in sequence: an\n",
      "next word predicted for sequence: an\n",
      "Iteration 2100\n",
      "Average Loss 2.42492450664\n",
      "Average Accuracy 25.0\n",
      "words in sequence: [',', 'until', 'an']\n",
      "next word in sequence: old\n",
      "next word predicted for sequence: old\n",
      "Iteration 2200\n",
      "Average Loss 2.6255010131\n",
      "Average Accuracy 17.0\n",
      "words in sequence: [',', 'until', 'an']\n",
      "next word in sequence: old\n",
      "next word predicted for sequence: ,\n",
      "Iteration 2300\n",
      "Average Loss 3.42965500247\n",
      "Average Accuracy 18.0\n",
      "words in sequence: ['this', 'proposal', 'met']\n",
      "next word in sequence: with\n",
      "next word predicted for sequence: .\n",
      "Iteration 2400\n",
      "Average Loss 3.81712133581\n",
      "Average Accuracy 25.0\n",
      "words in sequence: ['was', 'in', 'the']\n",
      "next word in sequence: neighbourhood\n",
      "next word predicted for sequence: that\n",
      "Iteration 2500\n",
      "Average Loss 2.7080274282\n",
      "Average Accuracy 34.0\n",
      "words in sequence: ['she', 'was', 'in']\n",
      "next word in sequence: the\n",
      "next word predicted for sequence: the\n",
      "Iteration 2600\n",
      "Average Loss 3.59275328019\n",
      "Average Accuracy 15.0\n",
      "words in sequence: ['easily', 'retire', 'while']\n",
      "next word in sequence: she\n",
      "next word predicted for sequence: the\n",
      "Iteration 2700\n",
      "Average Loss 2.31982569679\n",
      "Average Accuracy 34.0\n",
      "words in sequence: ['when', 'she', 'was']\n",
      "next word in sequence: about\n",
      "next word predicted for sequence: about\n",
      "Iteration 2800\n",
      "Average Loss 3.04050570916\n",
      "Average Accuracy 17.0\n",
      "words in sequence: ['know', 'when', 'she']\n",
      "next word in sequence: was\n",
      "next word predicted for sequence: approach\n",
      "Iteration 2900\n",
      "Average Loss 2.84519621808\n",
      "Average Accuracy 23.0\n",
      "words in sequence: ['this', 'means', 'we']\n",
      "next word in sequence: should\n",
      "next word predicted for sequence: a\n",
      "Iteration 3000\n",
      "Average Loss 2.65292499891\n",
      "Average Accuracy 21.0\n",
      "words in sequence: ['cat', '.', 'by']\n",
      "next word in sequence: this\n",
      "next word predicted for sequence: said\n",
      "Iteration 3100\n",
      "Average Loss 2.52225881515\n",
      "Average Accuracy 26.0\n",
      "words in sequence: ['round', 'the', 'neck']\n",
      "next word in sequence: of\n",
      "next word predicted for sequence: of\n",
      "Iteration 3200\n",
      "Average Loss 2.65115228362\n",
      "Average Accuracy 20.0\n",
      "words in sequence: ['a', 'ribbon', 'round']\n",
      "next word in sequence: the\n",
      "next word predicted for sequence: common\n",
      "Iteration 3300\n",
      "Average Loss 3.31760716446\n",
      "Average Accuracy 37.0\n",
      "words in sequence: ['bell', 'be', 'procured']\n",
      "next word in sequence: ,\n",
      "next word predicted for sequence: .\n",
      "Iteration 3400\n",
      "Average Loss 3.63770693027\n",
      "Average Accuracy 23.0\n",
      "words in sequence: ['procured', ',', 'and']\n",
      "next word in sequence: attached\n",
      "next word predicted for sequence: he\n",
      "Iteration 3500\n",
      "Average Loss 2.86864678949\n",
      "Average Accuracy 23.0\n",
      "words in sequence: ['procured', ',', 'and']\n",
      "next word in sequence: attached\n",
      "next word predicted for sequence: propose\n",
      "Iteration 3600\n",
      "Average Loss 2.19270499755\n",
      "Average Accuracy 36.0\n",
      "words in sequence: ['be', 'procured', ',']\n",
      "next word in sequence: and\n",
      "next word predicted for sequence: and\n",
      "Iteration 3700\n",
      "Average Loss 1.42947487237\n",
      "Average Accuracy 54.0\n",
      "words in sequence: ['be', 'procured', ',']\n",
      "next word in sequence: and\n",
      "next word predicted for sequence: but\n",
      "Iteration 3800\n",
      "Average Loss 3.27166086889\n",
      "Average Accuracy 25.0\n",
      "words in sequence: ['propose', 'that', 'a']\n",
      "next word in sequence: small\n",
      "next word predicted for sequence: that\n",
      "Iteration 3900\n",
      "Average Loss 2.64640145554\n",
      "Average Accuracy 32.0\n",
      "words in sequence: [',', 'therefore', ',']\n",
      "next word in sequence: to\n",
      "next word predicted for sequence: to\n",
      "Iteration 4000\n",
      "Average Loss 1.84041168381\n",
      "Average Accuracy 55.0\n",
      "words in sequence: [',', 'therefore', ',']\n",
      "next word in sequence: to\n",
      "next word predicted for sequence: to\n",
      "Iteration 4100\n",
      "Average Loss 2.32570329591\n",
      "Average Accuracy 37.0\n",
      "words in sequence: ['therefore', ',', 'to']\n",
      "next word in sequence: propose\n",
      "next word predicted for sequence: propose\n",
      "Iteration 4200\n",
      "Average Loss 1.99571153053\n",
      "Average Accuracy 46.0\n",
      "words in sequence: ['therefore', ',', 'to']\n",
      "next word in sequence: propose\n",
      "next word predicted for sequence: could\n",
      "Iteration 4300\n",
      "Average Loss 3.03015766364\n",
      "Average Accuracy 26.0\n",
      "words in sequence: ['i', 'venture', ',']\n",
      "next word in sequence: therefore\n",
      "next word predicted for sequence: but\n",
      "Iteration 4400\n",
      "Average Loss 2.60744434005\n",
      "Average Accuracy 33.0\n",
      "words in sequence: ['i', 'venture', ',']\n",
      "next word in sequence: therefore\n",
      "next word predicted for sequence: therefore\n",
      "Iteration 4500\n",
      "Average Loss 2.99870323498\n",
      "Average Accuracy 26.0\n",
      "words in sequence: ['from', 'her', '.']\n",
      "next word in sequence: i\n",
      "next word predicted for sequence: the\n",
      "Iteration 4600\n",
      "Average Loss 1.95537311258\n",
      "Average Accuracy 47.0\n",
      "words in sequence: [',', 'we', 'could']\n",
      "next word in sequence: easily\n",
      "next word predicted for sequence: easily\n",
      "Iteration 4700\n",
      "Average Loss 1.75217968211\n",
      "Average Accuracy 52.0\n",
      "words in sequence: ['could', 'receive', 'some']\n",
      "next word in sequence: signal\n",
      "next word predicted for sequence: signal\n",
      "Iteration 4800\n",
      "Average Loss 2.65510492053\n",
      "Average Accuracy 33.0\n",
      "words in sequence: [',', 'if', 'we']\n",
      "next word in sequence: could\n",
      "next word predicted for sequence: could\n",
      "Iteration 4900\n",
      "Average Loss 2.37987981963\n",
      "Average Accuracy 38.0\n",
      "words in sequence: ['we', 'could', 'receive']\n",
      "next word in sequence: some\n",
      "next word predicted for sequence: some\n",
      "Iteration 5000\n",
      "Average Loss 2.21162850073\n",
      "Average Accuracy 41.0\n",
      "words in sequence: [',', 'if', 'we']\n",
      "next word in sequence: could\n",
      "next word predicted for sequence: could\n",
      "Iteration 5100\n",
      "Average Loss 2.24300818422\n",
      "Average Accuracy 40.0\n",
      "words in sequence: ['us', '.', 'now']\n",
      "next word in sequence: ,\n",
      "next word predicted for sequence: we\n",
      "Iteration 5200\n",
      "Average Loss 2.04295066046\n",
      "Average Accuracy 38.0\n",
      "words in sequence: ['enemy', 'approaches', 'us']\n",
      "next word in sequence: .\n",
      "next word predicted for sequence: .\n",
      "Iteration 5300\n",
      "Average Loss 1.83431948919\n",
      "Average Accuracy 51.0\n",
      "words in sequence: ['the', 'enemy', 'approaches']\n",
      "next word in sequence: us\n",
      "next word predicted for sequence: old\n",
      "Iteration 5400\n",
      "Average Loss 2.46879898298\n",
      "Average Accuracy 31.0\n",
      "words in sequence: ['the', 'enemy', 'approaches']\n",
      "next word in sequence: us\n",
      "next word predicted for sequence: a\n",
      "Iteration 5500\n",
      "Average Loss 2.03672774923\n",
      "Average Accuracy 40.0\n",
      "words in sequence: ['manner', 'in', 'which']\n",
      "next word in sequence: the\n",
      "next word predicted for sequence: the\n",
      "Iteration 5600\n",
      "Average Loss 2.32056522219\n",
      "Average Accuracy 42.0\n",
      "words in sequence: ['and', 'treacherous', 'manner']\n",
      "next word in sequence: in\n",
      "next word predicted for sequence: all\n",
      "Iteration 5700\n",
      "Average Loss 1.91933244148\n",
      "Average Accuracy 45.0\n",
      "words in sequence: ['in', 'the', 'sly']\n",
      "next word in sequence: and\n",
      "next word predicted for sequence: and\n",
      "Iteration 5800\n",
      "Average Loss 1.81386675722\n",
      "Average Accuracy 54.0\n",
      "words in sequence: ['consists', 'in', 'the']\n",
      "next word in sequence: sly\n",
      "next word predicted for sequence: sly\n",
      "Iteration 5900\n",
      "Average Loss 1.84132800767\n",
      "Average Accuracy 55.0\n",
      "words in sequence: ['our', 'chief', 'danger']\n",
      "next word in sequence: consists\n",
      "next word predicted for sequence: ,\n",
      "Optimization Finished.\n"
     ]
    }
   ],
   "source": [
    "start = np.random.randint(0, no_of_words_to_be_passed_as_input_at_a_time+1) # Returns an integer between 0 and 3 inclusive.\n",
    "max_iterations = 6000\n",
    "i = 0\n",
    "loss_total = 0\n",
    "acc_total = 0\n",
    "print_after_every_i_iteration = 100\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "end_index = no_of_words_to_be_passed_as_input_at_a_time + 1\n",
    "\n",
    "while i < max_iterations:\n",
    "    \n",
    "    if start > (len(training_data) - end_index):\n",
    "        start = np.random.randint(0, no_of_words_to_be_passed_as_input_at_a_time+1)\n",
    "    \n",
    "    ''' Preparing Input for the Network'''\n",
    "    \n",
    "    ''' list of words. How many words? equal to no_of_words_to_be_passed_as_input_at_a_time'''\n",
    "    # Assume sentence : Chinto and Pinto are brothers.\n",
    "    # [ 'Chinto' , 'and', 'Pinto' ] , 3 words in sequence from the document\n",
    "    list_of_words = [ training_data[j] for j in range(start, start+no_of_words_to_be_passed_as_input_at_a_time)]\n",
    "    \n",
    "    # [ 11 , 2, 15 ], lower index means no of occurrence of that particular word was more in the document\n",
    "    ix_of_corresponding_words = [ word_to_ix[word] for word in list_of_words]\n",
    "    \n",
    "    ix_of_corresponding_words_modified = list()\n",
    "    # [ [11], [2], [15] ] => its a list but if it were numpy array its shape would be (3,1)\n",
    "    # where no_of_words_to_be_passed_as_input_at_a_time = 3\n",
    "    for ix in ix_of_corresponding_words:\n",
    "        ix_of_corresponding_words_modified.append([ix])\n",
    "        \n",
    "#     print(ix_of_corresponding_words_modified)\n",
    "    # three_dimensional_input = [ [ [11], [2], [15] ] ] => shape (1, 3, 1)\n",
    "    three_dimensional_input = np.reshape(ix_of_corresponding_words_modified, (-1, no_of_words_to_be_passed_as_input_at_a_time, 1))\n",
    "    \n",
    "    \n",
    "    ''' Preparing output for the Network'''\n",
    "    \n",
    "    # Get the index of the word after Pinto => index for 'are'\n",
    "    output_word = training_data[start+no_of_words_to_be_passed_as_input_at_a_time]\n",
    "    # suppose ix = 5\n",
    "    ix_of_output_word = word_to_ix[output_word]\n",
    "    \n",
    "    # One hot encode the output word's index, assuming vocab_size = 7\n",
    "    # \n",
    "    one_hot_encoded_output = np.zeros((vocab_size), dtype=float) # 1-d numpy array\n",
    "    one_hot_encoded_output[ix_of_output_word] = 1.0 # [ 0 0 0 0 1.0 0 0 ]\n",
    "    one_hot_encoded_reshaped = np.reshape(one_hot_encoded_output, (1,-1)) # 2-d numpy array # [ [0 0 0 0 1.0 0 0] ]\n",
    "    \n",
    "    ''' Calling Tensorflow Operations '''\n",
    "    _, acc, loss, onehot_pred = sess.run([optimizer, accuracy, cost, pred], \\\n",
    "                                                feed_dict={x: three_dimensional_input, y: one_hot_encoded_reshaped})\n",
    "    \n",
    "    loss_total = loss_total + loss\n",
    "    acc_total = acc_total + acc\n",
    "    \n",
    "    \n",
    "    if i%print_after_every_i_iteration == 0:\n",
    "        print(\"Iteration\", i)\n",
    "        print(\"Average Loss\", loss_total/print_after_every_i_iteration)\n",
    "        print(\"Average Accuracy\", (acc_total*100)/print_after_every_i_iteration)\n",
    "        \n",
    "        acc_total = 0\n",
    "        loss_total = 0\n",
    "        \n",
    "        random_words = [ training_data[z] for z in range(start, start+no_of_words_to_be_passed_as_input_at_a_time) ]\n",
    "        next_word = training_data[start+no_of_words_to_be_passed_as_input_at_a_time]\n",
    "        predicted_next_word = ix_to_word[int(tf.argmax(onehot_pred, 1).eval(session=sess))]\n",
    "        print(\"words in sequence:\", random_words)\n",
    "        print(\"next word in sequence:\", next_word)\n",
    "        print(\"next word predicted for sequence:\", predicted_next_word)\n",
    "        \n",
    "    \n",
    "    i = i + 1\n",
    "    start = start + no_of_words_to_be_passed_as_input_at_a_time + 1\n",
    "    \n",
    "print(\"Optimization Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 3  words\n",
      "had a general\n",
      "No of words that the predicted sentence should contain?\n",
      "32\n",
      "had a general would to until mouse signal , which could a neighbourhood the outwit , treacherous . treacherous mouse easy mouse should , and could , and some , and some , and some\n"
     ]
    }
   ],
   "source": [
    "''' Testing '''\n",
    "\n",
    "print(\"Enter\", no_of_words_to_be_passed_as_input_at_a_time, \" words\")\n",
    "sentence = input()\n",
    "sentence = sentence.strip()\n",
    "words = sentence.split(' ')\n",
    "\n",
    "words_converted_to_index = [word_to_ix[word] for word in words]\n",
    "\n",
    "print(\"No of words that the predicted sentence should contain?\")\n",
    "n = int(input())\n",
    "\n",
    "for i in range(n):\n",
    "    three_dimensional_test_input = np.reshape(words_converted_to_index, (-1, no_of_words_to_be_passed_as_input_at_a_time, 1))\n",
    "    onehot_pred = sess.run(pred, feed_dict={x:three_dimensional_test_input})\n",
    "    onehot_pred_index = int(tf.argmax(onehot_pred,1).eval(session = sess))\n",
    "    words_converted_to_index = words_converted_to_index[1:]\n",
    "    words_converted_to_index.append(onehot_pred_index)\n",
    "    \n",
    "    sentence = sentence + ' ' + ix_to_word[onehot_pred_index]\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
